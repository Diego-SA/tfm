{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFM: Selección del modelo de predicción\n",
    "## Diego Sanz Alonso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Importar librerías y creación de funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Only show warnings once\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import neighbors, tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Leer datos y crear conjunto de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "Clases sin bugs (negativos):  174396\n",
      "Clases con bugs (positivos):  8275\n",
      "Proporcion de clases con bugs:  4.53 %\n"
     ]
    }
   ],
   "source": [
    "input_data = \"datasets/dataframes/\"\n",
    "df_file = \"classes_processed_v1.csv\"\n",
    "\n",
    "print(\"Reading data\")\n",
    "\n",
    "# Classes dataframe\n",
    "classes_df = pd.read_csv(input_data + df_file)\n",
    "\n",
    "label = \"Has bugs\"\n",
    "\n",
    "# Atts and label(binary -> False: no bugs, True: bugs)\n",
    "classes_df_atts = classes_df.drop([label], axis = 1)\n",
    "classes_df_label = classes_df[label]\n",
    "\n",
    "print(\"Clases sin bugs (negativos): \",len(classes_df_label[~classes_df_label]))\n",
    "print(\"Clases con bugs (positivos): \", len(classes_df_label[classes_df_label]))\n",
    "print(\"Proporcion de clases con bugs: \", round(len(classes_df_label[classes_df_label])/len(classes_df_label)*100,2),'%')\n",
    "\n",
    "# Train / Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(classes_df_atts, classes_df_label, test_size=0.33, stratify=classes_df_label)\n",
    "\n",
    "\n",
    "# Train and test df\n",
    "train_df = X_train.copy()\n",
    "train_df[label] = y_train.copy()\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df[label] = y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tryModel(model, X_train, y_train, X_test, y_test):\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    prediction = clf.predict(X_test) \n",
    "    precision = precision_score(y_test,prediction)\n",
    "    recall = recall_score(y_test,prediction)\n",
    "    f1 = f1_score(y_test,prediction)\n",
    "    roc = roc_auc_score(y_test, prediction)\n",
    "    return precision, recall, f1, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3075117370892019,\n",
       " 0.2878066642255584,\n",
       " 0.2973330811424248,\n",
       " 0.6285256670852384)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dado un modelo, realiza la validacion cruzada\n",
    "model = tree.DecisionTreeClassifier()\n",
    "tryModel(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a intentar optimizar 2 de los muchos parámetros que puede tener el árbol de decisión:\n",
    "\n",
    "* **Profundidad máxima** que pueda alcanzar el árbol. Por defecto el árbol se expande entero (**None**), pero debemos evitar ramificar demasiadas hojas y controlar el sobreajuste.\n",
    "* **Número mínimo de ejemplos que debe tener en una hoja** para poder particionarse. En caso de que se llegue a un nodo que no sea hoja pero número de instancias es menor al requerido, entonces el algoritmo no ramifica y lo convierte en hoja.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bruteTree(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Obtener la mejor configuración para un clasificador de\n",
    "    árbol de predicción mediante búsqueda por fuerza bruta.\"\"\"\n",
    "    # Puntuación inicial\n",
    "    mejorScore = 0\n",
    "    mejorconf = None\n",
    "\n",
    "    # Iterar configuraciones\n",
    "    for i, j in [(i, j) for i in [None] + list(range(1,20,2)) for j in list(range(2,20,3))]:\n",
    "        model = tree.DecisionTreeClassifier(max_depth = i, min_samples_split = j)\n",
    "        # Validacion cruzada para testear parametros\n",
    "        scores = cross_val_score(model, X_train, y_train, cv = 5, scoring=\"f1\")\n",
    "        score = scores.mean()\n",
    "        # Actualizar puntuación\n",
    "        if (score > mejorScore):\n",
    "            mejorScore = score\n",
    "            mejorconf = (i,j)\n",
    "    # Devolve mejor configuración\n",
    "    return mejorconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bruteTree(X_train, y_train, X_test, y_test)\n",
    "# Resultados: (None, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que ha tomado los valores por defecto de este modelo. Ahora, vamos a intentar seleccionar algunas variables en lugar de utilizar todas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "def bestNAtts(X_train, y_train, X_test, y_test):\n",
    "    n_atts = 0\n",
    "    best_K = None\n",
    "    best_score = 0\n",
    "    for i in range(len(X_train.columns)):\n",
    "        n_atts = i + 1\n",
    "        X_train_transformed = SelectKBest(chi2, k=n_atts).fit_transform(X_train,y_train)\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "        scores = cross_val_score(model, X_train_transformed, y_train, cv = 10, scoring=\"f1\")\n",
    "        score = scores.mean()\n",
    "        if (score > best_score):\n",
    "            print(\"Mejora con \", n_atts, \"atributos, consiguiendo un F1-Score en la validación cruzada de \", score)\n",
    "            best_score = scores.mean()\n",
    "            best_K = n_atts\n",
    "    return best_K, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bestNAtts(X_train, y_train, X_test, y_test)\n",
    "# Resultado: 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3108320251177394, 0.2900036616623947, 0.3000568289448759, 0.629745797052462)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dado un modelo, realiza la validacion cruzada\n",
    "transformer = SelectKBest(chi2, k=69)\n",
    "X_train_transformed = transformer.fit_transform(X_train,y_train)\n",
    "X_test_transformed = transformer.transform(X_test)\n",
    "model = tree.DecisionTreeClassifier()\n",
    "tryModel(model, X_train_transformed, y_train, X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1) Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a eliminar parte de los casos positivos de entrenamiento para intentar tener un mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undersampling(df, frac_negatives = 0.5):\n",
    "    # Positive cases\n",
    "    train_df_positive = df[df[label]]\n",
    "    # Negative cases -> Delete some cases\n",
    "    train_df_negative = df[~df[label]]\n",
    "    train_df_negative = train_df_negative.sample(frac = frac_negatives)\n",
    "    # Join negative and positives cases\n",
    "    train_df_undersampling = train_df_positive.append(train_df_negative).sample(frac=1)\n",
    "    # Separate in attributes and label\n",
    "    X_undersampling = train_df_undersampling.drop(label, 1)\n",
    "    y_undersampling = train_df_undersampling[label]\n",
    "\n",
    "    return X_undersampling, y_undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligiendo 90.0 % de los datos negativos. Precisión 0.2905 ;Recall 0.2929 ;F1 0.2917 ;ROC  0.6295\n",
      "Eligiendo 80.0 % de los datos negativos. Precisión 0.279 ;Recall 0.3197 ;F1 0.298 ;ROC  0.6402\n",
      "Eligiendo 70.0 % de los datos negativos. Precisión 0.2821 ;Recall 0.3398 ;F1 0.3083 ;ROC  0.6494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bestNegFrac(df):\n",
    "    # Dividir conjunto de entrenamiento en otro conjunto de entrenamiento y test\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(classes_df_atts, classes_df_label, test_size=0.33, stratify=classes_df_label)\n",
    "    _train_df = _X_train.copy()\n",
    "    _train_df[label] = _y_train.copy()\n",
    "    _test_df = _X_test.copy()\n",
    "    _test_df[label] = _y_test.copy()\n",
    "    \n",
    "    # Para cada porcentaje de casos negativos entrenar y ver score\n",
    "    frac_negatives = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.025, 0]\n",
    "    best_frac = None\n",
    "    best_score = 0\n",
    "    for frac in frac_negatives:\n",
    "        _X_under, _y_under = undersampling(_train_df, frac_negatives = frac)\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "        p, r, s, a = tryModel(model, _X_under, _y_under, _X_test, _y_test)\n",
    "        score = s\n",
    "        if (score > best_score):\n",
    "            print(\"Eligiendo\", frac*100, '% de los datos negativos. Precisión',round(p,4),';Recall',round(r,4),';F1',round(s,4),';ROC ',round(a,4))\n",
    "            best_frac = frac\n",
    "            best_score = score\n",
    "    return best_frac\n",
    "bestNegFrac(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases sin bugs (negativos):  81792\n",
      "Clases con bugs (positivos):  5544\n",
      "Proporcion de clases con bugs:  6.35 %\n"
     ]
    }
   ],
   "source": [
    "X_undersampling, y_undersampling = undersampling(train_df, frac_negatives = 0.7)\n",
    "print(\"Clases sin bugs (negativos): \",len(y_undersampling[~y_undersampling]))\n",
    "print(\"Clases con bugs (positivos): \", len(y_undersampling[y_undersampling]))\n",
    "print(\"Proporcion de clases con bugs: \", round(len(y_undersampling[y_undersampling])/len(y_undersampling)*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2605612998522895,\n",
       " 0.32295862321493957,\n",
       " 0.2884238064094179,\n",
       " 0.6397333819103316)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dado un modelo, realiza la validacion cruzada\n",
    "model = tree.DecisionTreeClassifier()\n",
    "tryModel(model, X_undersampling, y_undersampling, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2) Replicar casos positivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a intentar lo inverso: aumentar el número de casos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oversampling(df, frac_positives = 2):\n",
    "    # Positive cases -> Add some cases\n",
    "    train_df_positive = df[df[label]]\n",
    "    train_df_positive = train_df_positive.append(train_df_positive.sample(frac=frac_positives-1))\n",
    "    # Negative cases \n",
    "    train_df_negative = df[~df[label]]\n",
    "    # Join negative and positives cases\n",
    "    train_df_undersampling = train_df_positive.append(train_df_negative).sample(frac=1)\n",
    "    # Separate in attributes and label\n",
    "    X_undersampling = train_df_undersampling.drop(label, 1)\n",
    "    y_undersampling = train_df_undersampling[label]\n",
    "\n",
    "    return X_undersampling, y_undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligiendo 100 % de los datos positivos. Precisión 0.3047 Recall 0.2896 F1 0.297 ROC  0.6291\n",
      "Eligiendo 110 % de los datos positivos. Precisión 0.3139 Recall 0.3017 F1 0.3077 ROC  0.6352\n",
      "Eligiendo 140 % de los datos positivos. Precisión 0.3102 Recall 0.3149 F1 0.3126 ROC  0.6408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bestPosFrac(df):\n",
    "    # Dividir conjunto de entrenamiento en otro conjunto de entrenamiento y test\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(classes_df_atts, classes_df_label, test_size=0.33, stratify=classes_df_label)\n",
    "    _train_df = _X_train.copy()\n",
    "    _train_df[label] = _y_train.copy()\n",
    "    _test_df = _X_test.copy()\n",
    "    _test_df[label] = _y_test.copy()\n",
    "    \n",
    "    # Para cada porcentaje de casos positivos entrenar y ver score\n",
    "    frac_positives = [1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2]\n",
    "    best_frac = None\n",
    "    best_score = 0\n",
    "    for frac in frac_positives:\n",
    "        _X_under, _y_under = oversampling(_train_df, frac_positives = frac)\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "        p, r, s, a = tryModel(model, _X_under, _y_under, _X_test, _y_test)\n",
    "        score = s\n",
    "        if (score > best_score):\n",
    "            print(\"Eligiendo\", round(frac*100), '% de los datos positivos. Precisión',round(p,4),'Recall',round(r,4),'F1',round(s,4),'ROC ',round(a,4))\n",
    "            best_frac = frac\n",
    "            best_score = score\n",
    "    return best_frac\n",
    "bestPosFrac(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases sin bugs (negativos):  116845\n",
      "Clases con bugs (positivos):  7762\n",
      "Proporcion de clases con bugs:  6.23 %\n"
     ]
    }
   ],
   "source": [
    "X_oversampling, y_oversampling = oversampling(train_df, frac_positives = 1.4)\n",
    "print(\"Clases sin bugs (negativos): \",len(y_oversampling[~y_oversampling]))\n",
    "print(\"Clases con bugs (positivos): \", len(y_oversampling[y_oversampling]))\n",
    "print(\"Proporcion de clases con bugs: \", round(len(y_oversampling[y_oversampling])/len(y_oversampling)*100,2),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29933481152993346,\n",
       " 0.2965946539729037,\n",
       " 0.2979584329593526,\n",
       " 0.6318249807196624)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dado un modelo, realiza la validacion cruzada\n",
    "model = tree.DecisionTreeClassifier()\n",
    "tryModel(model, X_oversampling, y_oversampling, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2776782515227517,\n",
       " 0.28377883559135847,\n",
       " 0.28069540021731254,\n",
       " 0.6243745179677005)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth, min_samples = bruteTree(X_oversampling, y_oversampling, X_test, y_test)\n",
    "model = tree.DecisionTreeClassifier(max_depth = max_depth, min_samples_split = min_samples)\n",
    "tryModel(model, X_oversampling, y_oversampling, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4) Combinar ambas opciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a bajar el número de casos negativos y subir el de positivos de manera simultánea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overundersampling(df, frac_positives = 2, frac_negatives = 0.5):\n",
    "    # Positive cases -> Add some cases\n",
    "    train_df_positive = df[df[label]]\n",
    "    train_df_positive = train_df_positive.append(train_df_positive.sample(frac=frac_positives-1))\n",
    "    # Negative cases -> Delete some cases\n",
    "    train_df_negative = df[~df[label]]\n",
    "    train_df_negative = train_df_negative.sample(frac = frac_negatives)\n",
    "    # Join negative and positives cases\n",
    "    train_df_overundersampling = train_df_positive.append(train_df_negative).sample(frac=1)\n",
    "    # Separate in attributes and label\n",
    "    X_overundersampling = train_df_overundersampling.drop(label, 1)\n",
    "    y_overundersampling = train_df_overundersampling[label]\n",
    "\n",
    "    return X_overundersampling, y_overundersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligiendo 100 % de los datos positivos y 100 % de negativos: Precisión 0.3018 Recall 0.2992 F1 0.3005 ROC 0.6332\n",
      "Eligiendo 100 % de los datos positivos y 80 % de negativos: Precisión 0.2831 Recall 0.3255 F1 0.3028 ROC 0.6432\n",
      "Eligiendo 110 % de los datos positivos y 80 % de negativos: Precisión 0.2822 Recall 0.3317 F1 0.3049 ROC 0.6458\n",
      "Eligiendo 140 % de los datos positivos y 100 % de negativos: Precisión 0.3093 Recall 0.3101 F1 0.3097 ROC 0.6386\n",
      "Eligiendo 150 % de los datos positivos y 80 % de negativos: Precisión 0.2862 Recall 0.3435 F1 0.3123 ROC 0.6514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.5, 0.8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bestFracs(df):\n",
    "    # Dividir conjunto de entrenamiento en otro conjunto de entrenamiento y test\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(classes_df_atts, classes_df_label, test_size=0.33, stratify=classes_df_label)\n",
    "    _train_df = _X_train.copy()\n",
    "    _train_df[label] = _y_train.copy()\n",
    "    _test_df = _X_test.copy()\n",
    "    _test_df[label] = _y_test.copy()\n",
    "    \n",
    "    # Para cada porcentaje de casos positivos entrenar y ver score\n",
    "    frac_positives = [1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2]\n",
    "    frac_negatives = [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.025, 0]\n",
    "    \n",
    "    best_frac = None\n",
    "    best_score = 0\n",
    "    for frac in frac_positives:\n",
    "        for frac2 in frac_negatives:\n",
    "            _X_overunder, _y_overunder = overundersampling(_train_df, frac_positives = frac, frac_negatives=frac2)\n",
    "            model = tree.DecisionTreeClassifier()\n",
    "            p, r, s, a = tryModel(model, _X_overunder, _y_overunder, _X_test, _y_test)\n",
    "            score = s\n",
    "            if (score > best_score):\n",
    "                print(\"Eligiendo\", round(frac*100), '% de los datos positivos y',round(frac2*100),'% de negativos: Precisión',round(p,4),'Recall',round(r,4),'F1',round(s,4),'ROC',round(a,4))\n",
    "                best_frac = (frac, frac2)\n",
    "                best_score = score\n",
    "    return best_frac\n",
    "bestFracs(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases sin bugs (negativos):  93476\n",
      "Clases con bugs (positivos):  8316\n",
      "Proporcion de clases con bugs:  8.17 %\n"
     ]
    }
   ],
   "source": [
    "X_overundersampling, y_overundersampling = overundersampling(train_df, frac_positives = 1.5, frac_negatives = 0.8)\n",
    "print(\"Clases sin bugs (negativos): \",len(y_overundersampling[~y_overundersampling]))\n",
    "print(\"Clases con bugs (positivos): \", len(y_overundersampling[y_overundersampling]))\n",
    "print(\"Proporcion de clases con bugs: \", round(len(y_overundersampling[y_overundersampling])/len(y_overundersampling)*100,2),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2732861973562865,\n",
       " 0.3255217868912486,\n",
       " 0.29712566844919786,\n",
       " 0.642222588290197)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dado un modelo, realiza la validacion cruzada\n",
    "model = tree.DecisionTreeClassifier()\n",
    "tryModel(model, X_overundersampling, y_overundersampling, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4) Regresión Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalLasso(model, X_train, y_train, X_test, y_test, threshold):\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    prediction = clf.predict(X_test)\n",
    "    prediction = prediction >= threshold\n",
    "    precision = precision_score(y_test,prediction)\n",
    "    recall = recall_score(y_test,prediction)\n",
    "    f1 = f1_score(y_test,prediction)\n",
    "    roc = roc_auc_score(y_test, prediction)\n",
    "    return precision, recall, f1, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4329896907216495,\n",
       " 0.015378982057854266,\n",
       " 0.029702970297029705,\n",
       " 0.5072116539800487)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.01)\n",
    "evalLasso(model, X_train, y_train, X_test, y_test, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a intentar optimizar el valor de alfa y el umbral a partir del cual consideramos que una clase es positiva (ya que usar un valor distinto del 0.5 que es el valor común puede darnos resultados mejores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bestLasso(X_train, y_train, X_test, y_test):\n",
    "    alphas = [0.001, 0.01] + [x for x in np.arange(0.1, 1.1, 0.1)]\n",
    "    thresholds = [x for x in np.arange(0,1.1,0.1)]\n",
    "    bestConfig = None\n",
    "    bestScore = 0\n",
    "    for alpha in alphas:\n",
    "        for threshold in thresholds:\n",
    "            model = linear_model.Lasso(alpha=alpha)\n",
    "            _, _, score, _ = evalLasso(model, X_train, y_train, X_test, y_test, threshold)\n",
    "            if (score > bestScore):\n",
    "                print(\"Alpha \", alpha, \" + Threshold \", threshold, \" Score \", score)\n",
    "                bestScore = score\n",
    "                bestConfig = (alpha, threshold)\n",
    "                \n",
    "    return bestConfig, bestScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bestLasso(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1917129560126107,\n",
       " 0.46759428780666423,\n",
       " 0.2719335604770017,\n",
       " 0.6870212407913098)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.001)\n",
    "evalLasso(model, X_train, y_train, X_test, y_test, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEFCAYAAADqujDUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20207ec9d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def printRecallPrecision():\n",
    "    alpha = 0.001\n",
    "    thresholds = [0.001, 0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for threshold in thresholds:\n",
    "        model = linear_model.Lasso(alpha=alpha)\n",
    "        precision, recall, score, roc = evalLasso(model, X_train, y_train, X_test, y_test, threshold)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "    plt.plot(thresholds, precisions, color='green')\n",
    "    plt.plot(thresholds, recalls, color='orange')\n",
    "    plt.xlabel('Thresholds')\n",
    "    plt.ylabel('Precision and recall')\n",
    "    plt.show();\n",
    "printRecallPrecision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos como, si tomamos como clases con Bugs aquellas con una probabilidad mayor que 0.1, en función del valor de la regularización escogida, iremos bajando el recall pero aumentando la precisión a medida que lo aumentemos. Aquí habría que valorar si es conveniente asegurar una buen precisión, para que siempre que avisemos sea por un fallo muy posible; o tenemos en cuenta los dos criterios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11285395370696745,\n",
       " 0.7034053460270963,\n",
       " 0.19450210094669165,\n",
       " 0.7205059952842299)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.01)\n",
    "evalLasso(model, X_train, y_train, X_test, y_test, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07086773280988395,\n",
       " 0.8989381179055291,\n",
       " 0.13137826773339042,\n",
       " 0.6698301300027898)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.01)\n",
    "evalLasso(model, X_train, y_train, X_test, y_test, 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47368421052631576,\n",
       " 0.013181984621017943,\n",
       " 0.025650160313501962,\n",
       " 0.5062434744567793)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.1)\n",
    "evalLasso(model, X_train, y_train, X_test, y_test, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11897889808222692,\n",
       " 0.6792383742218967,\n",
       " 0.20248881126514573,\n",
       " 0.7202815561401573)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed, y_transformed = undersampling(train_df, frac_negatives=0.5)\n",
    "model = linear_model.Lasso(alpha=0.01)\n",
    "evalLasso(model, X_transformed, y_transformed, X_test, y_test, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15024232633279483,\n",
       " 0.5789088246063713,\n",
       " 0.23856948845631507,\n",
       " 0.7117667961019033)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed, y_transformed = oversampling(train_df, frac_positives=1.5)\n",
    "model = linear_model.Lasso(alpha=0.01)\n",
    "evalLasso(model, X_transformed, y_transformed, X_test, y_test, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12694593829606568,\n",
       " 0.6569022336140607,\n",
       " 0.212773527842021,\n",
       " 0.7212592348240934)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed, y_transformed = overundersampling(train_df, frac_positives = 1.5, frac_negatives=0.5)\n",
    "model = linear_model.Lasso(alpha=0.01)\n",
    "evalLasso(model, X_transformed, y_transformed, X_test, y_test, 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43333333333333335,\n",
       " 0.04760161113145368,\n",
       " 0.08578027053777632,\n",
       " 0.5223238546873754)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tarda mucho en ejecutarse\n",
    "# model = svm.SVC()\n",
    "# tryModel(model, X_train, y_train, X_test, y_test)\n",
    "# Resultados: (0.43333333333333335, 0.04760161113145368, 0.08578027053777632, 0.5223238546873754)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que no clasifica casi datos como positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37449392712550605,\n",
       " 0.06774075430245331,\n",
       " 0.11472868217054263,\n",
       " 0.5311858017311645)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = svm.SVC()\n",
    "# tryModel(model, X_undersampling, y_undersampling, X_test, y_test)\n",
    "# Reultados: (0.37449392712550605, 0.06774075430245331, 0.11472868217054263, 0.5311858017311645)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3569553805774278,\n",
       " 0.09959721713658001,\n",
       " 0.15574005153163473,\n",
       " 0.5455415148601007)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = svm.SVC()\n",
    "# tryModel(model, X_oversampling, y_oversampling, X_test, y_test)\n",
    "# Resultados: (0.3569553805774278, 0.09959721713658001, 0.15574005153163473, 0.5455415148601007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29074074074074074,\n",
       " 0.11497619919443428,\n",
       " 0.16478614536866967,\n",
       " 0.5508331326982927)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = svm.SVC()\n",
    "# tryModel(model, X_overundersampling, y_overundersampling, X_test, y_test)\n",
    "# Resultados: (0.29074074074074074, 0.11497619919443428, 0.16478614536866967, 0.5508331326982927)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6666666666666666,\n",
       " 0.016843647015745148,\n",
       " 0.032857142857142856,\n",
       " 0.508222000741978)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "tryModel(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
