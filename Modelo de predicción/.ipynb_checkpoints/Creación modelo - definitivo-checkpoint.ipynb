{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# TFM: Selección del modelo de predicción\n",
    "## Diego Sanz Alonso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### 1) Importar librerías y creación de funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Only show warnings once\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import neighbors, tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import check_array\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### 2) Leer datos y crear conjunto de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\Modelo de predicción\\datasets\\dataframes\\\n",
      "elasticsearch_classes.csv\n",
      "Clases sin bugs (negativos):  65497\n",
      "Clases con bugs (positivos):  4313\n",
      "Proporcion de clases con bugs:  6.59 %\n",
      "2890\n",
      "1423\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#print(os.getcwd())\n",
    "input_data =  os.getcwd()+os.sep+\"datasets\"+os.sep+\"dataframes\"+os.sep\n",
    "df_file = \"elasticsearch_classes.csv\"\n",
    "\n",
    "print(\"Reading data\")\n",
    "print(input_data)\n",
    "print(df_file)\n",
    "\n",
    "# Classes dataframe\n",
    "classes_df = pd.read_csv(input_data + df_file,engine='python')\n",
    "\n",
    "classes_df['Has bugs'] = np.where(classes_df[\"Number of bugs\"]>0, 1, 0)\n",
    "classes_df.drop([\"Number of bugs\"], axis=1, inplace=True)\n",
    "\n",
    "label = 'Has bugs'\n",
    "classes_df_atts = classes_df.drop([label], axis = 1)\n",
    "serie = pd.Series(classes_df[label].copy())\n",
    "classes_df_label = pd.DataFrame(serie)\n",
    "\n",
    "\n",
    "pos=np.count_nonzero(classes_df_label)\n",
    "neg=len(classes_df_label)-pos\n",
    "print(\"Clases sin bugs (negativos): \",neg)\n",
    "print(\"Clases con bugs (positivos): \",pos)\n",
    "print(\"Proporcion de clases con bugs: \", round((pos/neg)*100,2),'%')\n",
    "\n",
    "\n",
    "# Train / Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(classes_df_atts, classes_df_label, test_size=0.33, stratify=classes_df_label)\n",
    "\n",
    "# Train and test df\n",
    "train_df = X_train.copy()\n",
    "train_df[label] = y_train\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df[label] = y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### 3) Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def tryModel(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    clf = model.fit(X_train, y_train)\n",
    "    prediction = clf.predict(X_test)\n",
    "    precision = precision_score(np.array(y_test),prediction)\n",
    "    recall = recall_score(y_test,prediction)\n",
    "    f1 = f1_score(y_test,prediction)\n",
    "    roc = roc_auc_score(y_test, prediction)\n",
    "    return precision, recall, f1, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3225806451612903,\n",
       " 0.32326071679550245,\n",
       " 0.3229203229203229,\n",
       " 0.6392847650597914)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dado un modelo, realiza la validacion cruzada\n",
    "model = tree.DecisionTreeClassifier()\n",
    "tryModel(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Vamos a intentar optimizar 2 de los muchos parámetros que puede tener el árbol de decisión:\n",
    "\n",
    "* **Profundidad máxima** que pueda alcanzar el árbol. Por defecto el árbol se expande entero (**None**), pero debemos evitar ramificar demasiadas hojas y controlar el sobreajuste.\n",
    "* **Número mínimo de ejemplos que debe tener en una hoja** para poder particionarse. En caso de que se llegue a un nodo que no sea hoja pero número de instancias es menor al requerido, entonces el algoritmo no ramifica y lo convierte en hoja.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def bruteTree(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Obtener la mejor configuración para un clasificador de\n",
    "    árbol de predicción mediante búsqueda por fuerza bruta.\"\"\"\n",
    "    # Puntuación inicial\n",
    "    mejorScore = 0\n",
    "    mejorconf = None\n",
    "\n",
    "    # Iterar configuraciones\n",
    "    for i, j in [(i, j) for i in [None] + list(range(1,20,2)) for j in list(range(2,20,3))]:\n",
    "        temp_tree = tree.DecisionTreeClassifier(max_depth = i, min_samples_split = j)\n",
    "        # Validacion cruzada para testear parametros\n",
    "        scores = cross_val_score(temp_tree, X_train, y_train, cv = 5, scoring=\"f1\")\n",
    "        score = scores.mean()\n",
    "        # Actualizar puntuación\n",
    "        if (score > mejorScore):\n",
    "            mejorScore = score\n",
    "            mejorconf = (i,j)\n",
    "    # Devolve mejor configuración\n",
    "    return mejorconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bruteTree(X_train, y_train, X_test, y_test)\n",
    "# Resultados: (None, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Vemos que ha tomado los valores por defecto de este modelo. Ahora, vamos a intentar seleccionar algunas variables en lugar de utilizar todas.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atributos en X: 106\n",
      "Atributos tras selección: 20\n",
      "Ranking: [ 19  45  47  16  48  49  23  55   4  53  27 100  75  20  88  82  86  65\n",
      "  83 103]\n",
      "(0.3177501826150475, 0.3056921995783556, 0.3116045845272207, 0.6312407331456433)\n",
      "(0.31409727947238253, 0.26774420238931834, 0.2890743550834598, 0.6146262071396048)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PABLO\n",
    "#SELECTED K BEST WITH ANOVA\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_classif\n",
    "%matplotlib inline\n",
    "import pylab\n",
    "\n",
    "K = 20\n",
    "ranking = SelectKBest(score_func=f_classif,k=K)\n",
    "ranking.fit(X_train, y_train)\n",
    "X_t_proyec = ranking.transform(X_train)\n",
    "X_T_proyec = ranking.transform(X_test)\n",
    "print(\"Atributos en X: {}\".format(X_train.shape[1]))\n",
    "print(\"Atributos tras selección: {}\".format(X_t_proyec.shape[1]))\n",
    "\n",
    "# ver qué variables han sido seleccionadas\n",
    "print(\"Ranking: {}\".format(np.argsort(ranking.scores_)[::-1][:K]))\n",
    "seleccionados = ranking.get_support()\n",
    "pylab.matshow(seleccionados.reshape(1,-1), cmap='prism')\n",
    "pylab.xlabel(\"Índice de la variable\")\n",
    "\n",
    "#validar\n",
    "model = tree.DecisionTreeClassifier()\n",
    "#model = linear_model.LogisticRegression()\n",
    "antes=tryModel(model, X_train, y_train, X_test, y_test)\n",
    "despues=tryModel(model, X_t_proyec, y_train, X_T_proyec, y_test)\n",
    "print(antes)\n",
    "print(despues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atributos en X: 106\n",
      "Atributos tras selección: 20\n",
      "Ranking: [ 82  93  75  83  55 100  80  42  53   4   9  43  27 103  67  88  65  90\n",
      "  22  20]\n",
      "(0.3170197224251278, 0.3049894588896697, 0.3108882521489971, 0.6308662307170996)\n",
      "(0.2972972972972973, 0.23963457484188336, 0.26536964980544747, 0.6011728275551078)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PABLO\n",
    "#SELECTED K BEST WITH MI\n",
    "from  sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_classif\n",
    "%matplotlib inline\n",
    "import pylab\n",
    "\n",
    "K = 20\n",
    "ranking_MI = SelectKBest(score_func=mutual_info_classif, k=K)\n",
    "ranking_MI.fit(X_train, y_train)\n",
    "X_seleccionMI = ranking_MI.transform(X_train)\n",
    "X_t_proyec = ranking_MI.transform(X_train)\n",
    "X_T_proyec = ranking_MI.transform(X_test)\n",
    "print(\"Atributos en X: {}\".format(X_train.shape[1]))\n",
    "print(\"Atributos tras selección: {}\".format(X_t_proyec.shape[1]))\n",
    "\n",
    "# ver qué variables han sido seleccionadas\n",
    "print(\"Ranking: {}\".format(np.argsort(ranking_MI.scores_)[::-1][:K]))\n",
    "seleccionados = ranking_MI.get_support()\n",
    "pylab.matshow(seleccionados.reshape(1,-1), cmap='prism')\n",
    "pylab.xlabel(\"Índice de la variable\")\n",
    "\n",
    "#validar\n",
    "model = tree.DecisionTreeClassifier()\n",
    "#model = linear_model.LogisticRegression()\n",
    "antes=tryModel(model, X_train, y_train, X_test, y_test)\n",
    "despues=tryModel(model, X_t_proyec, y_train, X_T_proyec, y_test)\n",
    "print(antes)\n",
    "print(despues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'unknown' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-41975fa90e54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mporcentajes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseleccion__percentile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mthis_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_df_atts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_df_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"f1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mscore_means\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mscore_stds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    752\u001b[0m             tasks = BatchedCalls(itertools.islice(iterator, batch_size),\n\u001b[0;32m    753\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_nested_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m                                  self._pickle_cache)\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                 \u001b[1;31m# No more tasks available in the iterator: tell caller to stop.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, iterator_slice, backend_and_jobs, pickle_cache)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_slice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend_and_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_slice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend_and_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    233\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m    234\u001b[0m     scores = parallel(\n\u001b[1;32m--> 235\u001b[1;33m         delayed(_fit_and_score)(\n\u001b[0m\u001b[0;32m    236\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    329\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_BaseKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m         \u001b[0mtest_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dropbox\\DOCENCIA\\TFM\\Diego Fermin\\tfm-repositorio\\env\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    634\u001b[0m             raise ValueError(\n\u001b[0;32m    635\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[1;32m--> 636\u001b[1;33m                     allowed_target_types, type_of_target_y))\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'unknown' instead."
     ]
    }
   ],
   "source": [
    "#PABLO\n",
    "#CV REGRESION LOGISTICA, F1 VS NUM VARIABLES con anova\n",
    "import pylab\n",
    "from sklearn.feature_selection import f_classif, SelectPercentile\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "seleccion = SelectPercentile(f_classif)\n",
    "pipe = Pipeline([('seleccion', seleccion), \n",
    "                 ('lr', LogisticRegression())])\n",
    "\n",
    "score_means = list()\n",
    "score_stds = list()\n",
    "porcentajes = list(np.linspace(10,100,5))\n",
    "\n",
    "for p in porcentajes:\n",
    "    pipe.set_params(seleccion__percentile=p)\n",
    "    this_scores = cross_val_score(pipe, classes_df_atts, classes_df_label, cv=StratifiedKFold(5),scoring=\"f1\",n_jobs=-1)\n",
    "    score_means.append(this_scores.mean())\n",
    "    score_stds.append(this_scores.std())\n",
    "\n",
    "pylab.errorbar(porcentajes, \n",
    "               score_means, np.array(score_stds))\n",
    "\n",
    "pylab.title('Bondad de LR aumentando el número de variables')\n",
    "pylab.xlabel('Porcentaje')\n",
    "pylab.ylabel('F1-measure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "def bestNAtts(X_train, y_train, X_test, y_test):\n",
    "    n_atts = 0\n",
    "    best_K = None\n",
    "    best_score = 0\n",
    "    for i in range(len(X_train.columns)):\n",
    "        n_atts = i + 1\n",
    "        X_train_transformed = SelectKBest(chi2, k=n_atts).fit_transform(X_train,y_train)\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "        scores = cross_val_score(model, X_train_transformed, y_train, cv = 10, scoring=\"f1\")\n",
    "        score = scores.mean()\n",
    "        if (score > best_score):\n",
    "            print(\"Mejora con \", n_atts, \"atributos, consiguiendo un F1-Score en la validación cruzada de \", score)\n",
    "            best_score = scores.mean()\n",
    "            best_K = n_atts\n",
    "    return best_K, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# bestNAtts(X_train, y_train, X_test, y_test)\n",
    "# Resultado: 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3108320251177394, 0.2900036616623947, 0.3000568289448759, 0.629745797052462)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dado un modelo, realiza la validacion cruzada\n",
    "transformer = SelectKBest(chi2, k=69)\n",
    "X_train_transformed = transformer.fit_transform(X_train,y_train)\n",
    "X_test_transformed = transformer.transform(X_test)\n",
    "model = tree.DecisionTreeClassifier()\n",
    "tryModel(model, X_train_transformed, y_train, X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "#### 3.1) Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Vamos a eliminar parte de los casos positivos de entrenamiento para intentar tener un mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def undersampling(df, frac_negatives = 0.5):\n",
    "    # Positive cases\n",
    "    train_df_positive = df[df[label]]\n",
    "    # Negative cases -> Delete some cases\n",
    "    train_df_negative = df[~df[label]]\n",
    "    train_df_negative = train_df_negative.sample(frac = frac_negatives)\n",
    "    # Join negative and positives cases\n",
    "    train_df_undersampling = train_df_positive.append(train_df_negative).sample(frac=1)\n",
    "    # Separate in attributes and label\n",
    "    X_undersampling = train_df_undersampling.drop(label, 1)\n",
    "    y_undersampling = train_df_undersampling[label]\n",
    "\n",
    "    return X_undersampling, y_undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligiendo 90.0 % de los datos negativos. Precisión 0.2905 ;Recall 0.2929 ;F1 0.2917 ;ROC  0.6295\n",
      "Eligiendo 80.0 % de los datos negativos. Precisión 0.279 ;Recall 0.3197 ;F1 0.298 ;ROC  0.6402\n",
      "Eligiendo 70.0 % de los datos negativos. Precisión 0.2821 ;Recall 0.3398 ;F1 0.3083 ;ROC  0.6494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bestNegFrac(df):\n",
    "    # Dividir conjunto de entrenamiento en otro conjunto de entrenamiento y test\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(classes_df_atts, classes_df_label, test_size=0.33, stratify=classes_df_label)\n",
    "    _train_df = _X_train.copy()\n",
    "    _train_df[label] = _y_train.copy()\n",
    "    _test_df = _X_test.copy()\n",
    "    _test_df[label] = _y_test.copy()\n",
    "    \n",
    "    # Para cada porcentaje de casos negativos entrenar y ver score\n",
    "    frac_negatives = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.025, 0]\n",
    "    best_frac = None\n",
    "    best_score = 0\n",
    "    for frac in frac_negatives:\n",
    "        _X_under, _y_under = undersampling(_train_df, frac_negatives = frac)\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "        p, r, s, a = tryModel(model, _X_under, _y_under, _X_test, _y_test)\n",
    "        score = s\n",
    "        if (score > best_score):\n",
    "            print(\"Eligiendo\", frac*100, '% de los datos negativos. Precisión',round(p,4),';Recall',round(r,4),';F1',round(s,4),';ROC ',round(a,4))\n",
    "            best_frac = frac\n",
    "            best_score = score\n",
    "    return best_frac\n",
    "bestNegFrac(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases sin bugs (negativos):  81792\n",
      "Clases con bugs (positivos):  5544\n",
      "Proporcion de clases con bugs:  6.35 %\n"
     ]
    }
   ],
   "source": [
    "X_undersampling, y_undersampling = undersampling(train_df, frac_negatives = 0.7)\n",
    "print(\"Clases sin bugs (negativos): \",len(y_undersampling[~y_undersampling]))\n",
    "print(\"Clases con bugs (positivos): \", len(y_undersampling[y_undersampling]))\n",
    "print(\"Proporcion de clases con bugs: \", round(len(y_undersampling[y_undersampling])/len(y_undersampling)*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2605612998522895,\n",
       " 0.32295862321493957,\n",
       " 0.2884238064094179,\n",
       " 0.6397333819103316)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dado un modelo, realiza la validacion cruzada\n",
    "model = tree.DecisionTreeClassifier()\n",
    "tryModel(model, X_undersampling, y_undersampling, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "#### 3.2) Replicar casos positivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Ahora vamos a intentar lo inverso: aumentar el número de casos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def oversampling(df, frac_positives = 2):\n",
    "    # Positive cases -> Add some cases\n",
    "    train_df_positive = df[df[label]]\n",
    "    train_df_positive = train_df_positive.append(train_df_positive.sample(frac=frac_positives-1))\n",
    "    # Negative cases \n",
    "    train_df_negative = df[~df[label]]\n",
    "    # Join negative and positives cases\n",
    "    train_df_undersampling = train_df_positive.append(train_df_negative).sample(frac=1)\n",
    "    # Separate in attributes and label\n",
    "    X_undersampling = train_df_undersampling.drop(label, 1)\n",
    "    y_undersampling = train_df_undersampling[label]\n",
    "\n",
    "    return X_undersampling, y_undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligiendo 100 % de los datos positivos. Precisión 0.3047 Recall 0.2896 F1 0.297 ROC  0.6291\n",
      "Eligiendo 110 % de los datos positivos. Precisión 0.3139 Recall 0.3017 F1 0.3077 ROC  0.6352\n",
      "Eligiendo 140 % de los datos positivos. Precisión 0.3102 Recall 0.3149 F1 0.3126 ROC  0.6408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bestPosFrac(df):\n",
    "    # Dividir conjunto de entrenamiento en otro conjunto de entrenamiento y test\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(classes_df_atts, classes_df_label, test_size=0.33, stratify=classes_df_label)\n",
    "    _train_df = _X_train.copy()\n",
    "    _train_df[label] = _y_train.copy()\n",
    "    _test_df = _X_test.copy()\n",
    "    _test_df[label] = _y_test.copy()\n",
    "    \n",
    "    # Para cada porcentaje de casos positivos entrenar y ver score\n",
    "    frac_positives = [1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2]\n",
    "    best_frac = None\n",
    "    best_score = 0\n",
    "    for frac in frac_positives:\n",
    "        _X_under, _y_under = oversampling(_train_df, frac_positives = frac)\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "        p, r, s, a = tryModel(model, _X_under, _y_under, _X_test, _y_test)\n",
    "        score = s\n",
    "        if (score > best_score):\n",
    "            print(\"Eligiendo\", round(frac*100), '% de los datos positivos. Precisión',round(p,4),'Recall',round(r,4),'F1',round(s,4),'ROC ',round(a,4))\n",
    "            best_frac = frac\n",
    "            best_score = score\n",
    "    return best_frac\n",
    "bestPosFrac(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases sin bugs (negativos):  116845\n",
      "Clases con bugs (positivos):  7762\n",
      "Proporcion de clases con bugs:  6.23 %\n"
     ]
    }
   ],
   "source": [
    "X_oversampling, y_oversampling = oversampling(train_df, frac_positives = 1.4)\n",
    "print(\"Clases sin bugs (negativos): \",len(y_oversampling[~y_oversampling]))\n",
    "print(\"Clases con bugs (positivos): \", len(y_oversampling[y_oversampling]))\n",
    "print(\"Proporcion de clases con bugs: \", round(len(y_oversampling[y_oversampling])/len(y_oversampling)*100,2),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29933481152993346,\n",
       " 0.2965946539729037,\n",
       " 0.2979584329593526,\n",
       " 0.6318249807196624)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dado un modelo, realiza la validacion cruzada\n",
    "model = tree.DecisionTreeClassifier()\n",
    "tryModel(model, X_oversampling, y_oversampling, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2776782515227517,\n",
       " 0.28377883559135847,\n",
       " 0.28069540021731254,\n",
       " 0.6243745179677005)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth, min_samples = bruteTree(X_oversampling, y_oversampling, X_test, y_test)\n",
    "model = tree.DecisionTreeClassifier(max_depth = max_depth, min_samples_split = min_samples)\n",
    "tryModel(model, X_oversampling, y_oversampling, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "#### 3.4) Combinar ambas opciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Ahora vamos a bajar el número de casos negativos y subir el de positivos de manera simultánea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def overundersampling(df, frac_positives = 2, frac_negatives = 0.5):\n",
    "    # Positive cases -> Add some cases\n",
    "    train_df_positive = df[df[label]]\n",
    "    train_df_positive = train_df_positive.append(train_df_positive.sample(frac=frac_positives-1))\n",
    "    # Negative cases -> Delete some cases\n",
    "    train_df_negative = df[~df[label]]\n",
    "    train_df_negative = train_df_negative.sample(frac = frac_negatives)\n",
    "    # Join negative and positives cases\n",
    "    train_df_overundersampling = train_df_positive.append(train_df_negative).sample(frac=1)\n",
    "    # Separate in attributes and label\n",
    "    X_overundersampling = train_df_overundersampling.drop(label, 1)\n",
    "    y_overundersampling = train_df_overundersampling[label]\n",
    "\n",
    "    return X_overundersampling, y_overundersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligiendo 100 % de los datos positivos y 100 % de negativos: Precisión 0.3018 Recall 0.2992 F1 0.3005 ROC 0.6332\n",
      "Eligiendo 100 % de los datos positivos y 80 % de negativos: Precisión 0.2831 Recall 0.3255 F1 0.3028 ROC 0.6432\n",
      "Eligiendo 110 % de los datos positivos y 80 % de negativos: Precisión 0.2822 Recall 0.3317 F1 0.3049 ROC 0.6458\n",
      "Eligiendo 140 % de los datos positivos y 100 % de negativos: Precisión 0.3093 Recall 0.3101 F1 0.3097 ROC 0.6386\n",
      "Eligiendo 150 % de los datos positivos y 80 % de negativos: Precisión 0.2862 Recall 0.3435 F1 0.3123 ROC 0.6514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.5, 0.8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bestFracs(df):\n",
    "    # Dividir conjunto de entrenamiento en otro conjunto de entrenamiento y test\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(classes_df_atts, classes_df_label, test_size=0.33, stratify=classes_df_label)\n",
    "    _train_df = _X_train.copy()\n",
    "    _train_df[label] = _y_train.copy()\n",
    "    _test_df = _X_test.copy()\n",
    "    _test_df[label] = _y_test.copy()\n",
    "    \n",
    "    # Para cada porcentaje de casos positivos entrenar y ver score\n",
    "    frac_positives = [1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2]\n",
    "    frac_negatives = [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.025, 0]\n",
    "    \n",
    "    best_frac = None\n",
    "    best_score = 0\n",
    "    for frac in frac_positives:\n",
    "        for frac2 in frac_negatives:\n",
    "            _X_overunder, _y_overunder = overundersampling(_train_df, frac_positives = frac, frac_negatives=frac2)\n",
    "            model = tree.DecisionTreeClassifier()\n",
    "            p, r, s, a = tryModel(model, _X_overunder, _y_overunder, _X_test, _y_test)\n",
    "            score = s\n",
    "            if (score > best_score):\n",
    "                print(\"Eligiendo\", round(frac*100), '% de los datos positivos y',round(frac2*100),'% de negativos: Precisión',round(p,4),'Recall',round(r,4),'F1',round(s,4),'ROC',round(a,4))\n",
    "                best_frac = (frac, frac2)\n",
    "                best_score = score\n",
    "    return best_frac\n",
    "bestFracs(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases sin bugs (negativos):  93476\n",
      "Clases con bugs (positivos):  8316\n",
      "Proporcion de clases con bugs:  8.17 %\n"
     ]
    }
   ],
   "source": [
    "X_overundersampling, y_overundersampling = overundersampling(train_df, frac_positives = 1.5, frac_negatives = 0.8)\n",
    "print(\"Clases sin bugs (negativos): \",len(y_overundersampling[~y_overundersampling]))\n",
    "print(\"Clases con bugs (positivos): \", len(y_overundersampling[y_overundersampling]))\n",
    "print(\"Proporcion de clases con bugs: \", round(len(y_overundersampling[y_overundersampling])/len(y_overundersampling)*100,2),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2732861973562865,\n",
       " 0.3255217868912486,\n",
       " 0.29712566844919786,\n",
       " 0.642222588290197)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dado un modelo, realiza la validacion cruzada\n",
    "model = tree.DecisionTreeClassifier()\n",
    "tryModel(model, X_overundersampling, y_overundersampling, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {}
   },
   "source": [
    "### 4) Regresión Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def evalLasso(model, X_train, y_train, X_test, y_test, threshold):\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    prediction = clf.predict(X_test)\n",
    "    prediction = prediction >= threshold\n",
    "    precision = precision_score(y_test,prediction)\n",
    "    recall = recall_score(y_test,prediction)\n",
    "    f1 = f1_score(y_test,prediction)\n",
    "    roc = roc_auc_score(y_test, prediction)\n",
    "    return precision, recall, f1, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4329896907216495,\n",
       " 0.015378982057854266,\n",
       " 0.029702970297029705,\n",
       " 0.5072116539800487)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.01)\n",
    "evalLasso(model, X_train, y_train, X_test, y_test, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Vamos a intentar optimizar el valor de alfa y el umbral a partir del cual consideramos que una clase es positiva (ya que usar un valor distinto del 0.5 que es el valor común puede darnos resultados mejores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def bestLasso(X_train, y_train, X_test, y_test):\n",
    "    alphas = [0.001, 0.01] + [x for x in np.arange(0.1, 1.1, 0.1)]\n",
    "    thresholds = [x for x in np.arange(0,1.1,0.1)]\n",
    "    bestConfig = None\n",
    "    bestScore = 0\n",
    "    for alpha in alphas:\n",
    "        for threshold in thresholds:\n",
    "            model = linear_model.Lasso(alpha=alpha)\n",
    "            _, _, score, _ = evalLasso(model, X_train, y_train, X_test, y_test, threshold)\n",
    "            if (score > bestScore):\n",
    "                print(\"Alpha \", alpha, \" + Threshold \", threshold, \" Score \", score)\n",
    "                bestScore = score\n",
    "                bestConfig = (alpha, threshold)\n",
    "                \n",
    "    return bestConfig, bestScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# bestLasso(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1917129560126107,\n",
       " 0.46759428780666423,\n",
       " 0.2719335604770017,\n",
       " 0.6870212407913098)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.001)\n",
    "evalLasso(model, X_train, y_train, X_test, y_test, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEFCAYAAADqujDUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20207ec9d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def printRecallPrecision():\n",
    "    alpha = 0.001\n",
    "    thresholds = [0.001, 0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for threshold in thresholds:\n",
    "        model = linear_model.Lasso(alpha=alpha)\n",
    "        precision, recall, score, roc = evalLasso(model, X_train, y_train, X_test, y_test, threshold)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "    plt.plot(thresholds, precisions, color='green')\n",
    "    plt.plot(thresholds, recalls, color='orange')\n",
    "    plt.xlabel('Thresholds')\n",
    "    plt.ylabel('Precision and recall')\n",
    "    plt.show();\n",
    "printRecallPrecision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Vemos como, si tomamos como clases con Bugs aquellas con una probabilidad mayor que 0.1, en función del valor de la regularización escogida, iremos bajando el recall pero aumentando la precisión a medida que lo aumentemos. Aquí habría que valorar si es conveniente asegurar una buen precisión, para que siempre que avisemos sea por un fallo muy posible; o tenemos en cuenta los dos criterios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11285395370696745,\n",
       " 0.7034053460270963,\n",
       " 0.19450210094669165,\n",
       " 0.7205059952842299)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.01)\n",
    "evalLasso(model, X_train, y_train, X_test, y_test, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07086773280988395,\n",
       " 0.8989381179055291,\n",
       " 0.13137826773339042,\n",
       " 0.6698301300027898)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.01)\n",
    "evalLasso(model, X_train, y_train, X_test, y_test, 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47368421052631576,\n",
       " 0.013181984621017943,\n",
       " 0.025650160313501962,\n",
       " 0.5062434744567793)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.1)\n",
    "evalLasso(model, X_train, y_train, X_test, y_test, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11897889808222692,\n",
       " 0.6792383742218967,\n",
       " 0.20248881126514573,\n",
       " 0.7202815561401573)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed, y_transformed = undersampling(train_df, frac_negatives=0.5)\n",
    "model = linear_model.Lasso(alpha=0.01)\n",
    "evalLasso(model, X_transformed, y_transformed, X_test, y_test, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15024232633279483,\n",
       " 0.5789088246063713,\n",
       " 0.23856948845631507,\n",
       " 0.7117667961019033)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed, y_transformed = oversampling(train_df, frac_positives=1.5)\n",
    "model = linear_model.Lasso(alpha=0.01)\n",
    "evalLasso(model, X_transformed, y_transformed, X_test, y_test, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12694593829606568,\n",
       " 0.6569022336140607,\n",
       " 0.212773527842021,\n",
       " 0.7212592348240934)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed, y_transformed = overundersampling(train_df, frac_positives = 1.5, frac_negatives=0.5)\n",
    "model = linear_model.Lasso(alpha=0.01)\n",
    "evalLasso(model, X_transformed, y_transformed, X_test, y_test, 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {}
   },
   "source": [
    "### 5) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43333333333333335,\n",
       " 0.04760161113145368,\n",
       " 0.08578027053777632,\n",
       " 0.5223238546873754)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tarda mucho en ejecutarse\n",
    "# model = svm.SVC()\n",
    "# tryModel(model, X_train, y_train, X_test, y_test)\n",
    "# Resultados: (0.43333333333333335, 0.04760161113145368, 0.08578027053777632, 0.5223238546873754)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Se puede ver que no clasifica casi datos como positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37449392712550605,\n",
       " 0.06774075430245331,\n",
       " 0.11472868217054263,\n",
       " 0.5311858017311645)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = svm.SVC()\n",
    "# tryModel(model, X_undersampling, y_undersampling, X_test, y_test)\n",
    "# Reultados: (0.37449392712550605, 0.06774075430245331, 0.11472868217054263, 0.5311858017311645)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3569553805774278,\n",
       " 0.09959721713658001,\n",
       " 0.15574005153163473,\n",
       " 0.5455415148601007)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = svm.SVC()\n",
    "# tryModel(model, X_oversampling, y_oversampling, X_test, y_test)\n",
    "# Resultados: (0.3569553805774278, 0.09959721713658001, 0.15574005153163473, 0.5455415148601007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29074074074074074,\n",
       " 0.11497619919443428,\n",
       " 0.16478614536866967,\n",
       " 0.5508331326982927)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = svm.SVC()\n",
    "# tryModel(model, X_overundersampling, y_overundersampling, X_test, y_test)\n",
    "# Resultados: (0.29074074074074074, 0.11497619919443428, 0.16478614536866967, 0.5508331326982927)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### 6) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-83661f389c58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtryModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "tryModel(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (tfm-repositorio)",
   "language": "python",
   "name": "pycharm-7e82875a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
